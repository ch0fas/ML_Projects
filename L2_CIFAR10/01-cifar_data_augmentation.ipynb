{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed15df2",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"https://samyzaf.com/ML/cifar10/cifar1.jpg\" width=\"380px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #bbc28d> **Trainning CNN'S - CIFAR Data Augmentation** </font>\n",
    "#### <font color= #2E9AFE> `Lab 2 - Machine Learning`</font>\n",
    "- <Strong> Sofía Maldonado, Diana Valdivia, Samantha Sánchez, Isabel Valladolid & Vivienne Toledo </Strong>\n",
    "- <Strong> Fecha </Strong>: 27/10/2025.\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Image retrieved from: https://samyzaf.com/ML/cifar10/cifar1.jpg</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb566c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592deb75",
   "metadata": {},
   "source": [
    "# <font color=#bbc28d>**Abstract**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15915405",
   "metadata": {},
   "source": [
    "# <font color=#bbc28d>**Configuration**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar la GPU o CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd1ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fijar un a semilla para reproducibilidad\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf72f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del batch de imágenes: torch.Size([512, 3, 32, 32])\n",
      "Tamaño del batch de etiquetas: torch.Size([512])\n",
      "Total train: 5280 | Total test: 1320\n"
     ]
    }
   ],
   "source": [
    "# # Convertir a tensor las imágenes originales\n",
    "# to_tensor = transforms.ToTensor()\n",
    "\n",
    "# # Data Augmentation: aplica variaciones aleatorias\n",
    "# augment = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),        # voltea horizontalmente\n",
    "#     transforms.RandomRotation(15),            # rota ±15 grados\n",
    "#     transforms.ColorJitter(0.2, 0.2, 0.2),    # cambia brillo, contraste y saturación\n",
    "#     transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # recorta aleatoriamente\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "\n",
    "# # Cargar el dataset de Cifar10 de los datasets de torch\n",
    "# base = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=to_tensor)\n",
    "\n",
    "\n",
    "# # Seleccioanr solo 60 imagenes pro clase [las originales]\n",
    "# idxs = []\n",
    "# for c in range(10):  # CIFAR-10 tiene 10 clases (0 a 9)\n",
    "#     count = 0\n",
    "#     for i, (_, label) in enumerate(base):\n",
    "#         if label == c:           # Si pertenece a la clase actual\n",
    "#             idxs.append(i)       # Guardamos su índice\n",
    "#             count += 1\n",
    "#             if count == 60:      # Tomamos solo 60 por clase\n",
    "#                 break\n",
    "\n",
    "# subset = Subset(base, idxs)\n",
    "\n",
    "# # Generar 10 versiones aumentadas por cada imagen original [600x10=6000]\n",
    "# augmented_imgs, augmented_labels = [], []\n",
    "\n",
    "# for i, (img, label) in enumerate(subset):\n",
    "#     for j in range(10):  # Generamos 10 augmentations por imagen\n",
    "#         # Fijamos semilla única para cada imagen/augmentación\n",
    "#         random.seed(SEED + i * 1000 + j)\n",
    "#         torch.manual_seed(SEED + i * 1000 + j)\n",
    "#         np.random.seed(SEED + i * 1000 + j)\n",
    "\n",
    "#         # Convertimos la imagen a PIL antes de aplicar augmentations\n",
    "#         img_aug = augment(transforms.ToPILImage()(img))\n",
    "        \n",
    "#         # Guardamos la imagen aumentada y su etiqueta\n",
    "#         augmented_imgs.append(img_aug)\n",
    "#         augmented_labels.append(label)\n",
    "\n",
    "# # Creamos una lista de tuplas (imagen, etiqueta)\n",
    "# augmented = list(zip(augmented_imgs, augmented_labels))\n",
    "\n",
    "\n",
    "# # Juntar las imagenes generadas con las originales [total:6600]\n",
    "# full = ConcatDataset([subset, augmented])\n",
    "\n",
    "# # Train/Test Split\n",
    "# train_size = int(0.8 * len(full))  # 80% para entrenamiento\n",
    "# test_size = len(full) - train_size # 20% para prueba\n",
    "\n",
    "# train_set, test_set = random_split(full, [train_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# # Crear los dataloaders para los modelos\n",
    "# train_loader = DataLoader(train_set, batch_size=512, shuffle=True)\n",
    "# test_loader = DataLoader(test_set, batch_size=512, shuffle=False)\n",
    "\n",
    "# Verificar todo\n",
    "# imgs, lbls = next(iter(train_loader))\n",
    "# print(\"Tamaño del batch de imágenes:\", imgs.shape) \n",
    "# print(\"Tamaño del batch de etiquetas:\", lbls.shape) \n",
    "# print(\"Total train:\", len(train_set), \"| Total test:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f4699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardaron correctamente las imagenes\n"
     ]
    }
   ],
   "source": [
    "# Convertir a tensor las imágenes originales\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Data Augmentation: aplica variaciones aleatorias\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),        # voltea horizontalmente\n",
    "    transforms.RandomRotation(15),            # rota ±15 grados\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),    # cambia brillo, contraste y saturación\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # recorta aleatoriamente\n",
    "    transforms.ToTensor()\n",
    " ])\n",
    "\n",
    "# Descargar el dataset de Cifar-10\n",
    "base = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=to_tensor)\n",
    "\n",
    "# Seleccioanr del dataset original solo 60 imágenes por clase [Total=600]\n",
    "idxs = []\n",
    "for c in range(10):\n",
    "    count = 0\n",
    "    for i, (_, label) in enumerate(base):\n",
    "        if label == c:\n",
    "            idxs.append(i)\n",
    "            count += 1\n",
    "            if count == 60:\n",
    "                break\n",
    "\n",
    "subset_imgs = []\n",
    "subset_labels = []\n",
    "\n",
    "for i in idxs:\n",
    "    img, lbl = base[i]\n",
    "    subset_imgs.append(img)\n",
    "    subset_labels.append(lbl)\n",
    "\n",
    "# Con Data Augmentation generar 10 variantes por imagen [Total=600x10=6000]\n",
    "augmented_imgs = []\n",
    "augmented_labels = []\n",
    "\n",
    "for i, img in enumerate(subset_imgs):\n",
    "    lbl = subset_labels[i]\n",
    "    for j in range(10):\n",
    "        seed = SEED + i * 1000 + j\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        img_aug = augment(transforms.ToPILImage()(img))\n",
    "        augmented_imgs.append(img_aug)\n",
    "        augmented_labels.append(lbl)\n",
    "\n",
    "# convierte las listas de imágenes y etiquetas a tensores de PyTorch\n",
    "# Originales\n",
    "subset_tensor = torch.stack(subset_imgs)         # [600, 3, 32, 32]\n",
    "subset_labels_tensor = torch.tensor(subset_labels)  # [600]\n",
    "\n",
    "# Aumentadas\n",
    "aug_tensor = torch.stack(augmented_imgs)        # [6000, 3, 32, 32]\n",
    "aug_labels_tensor = torch.tensor(augmented_labels)  # [6000]\n",
    "\n",
    "# Juntar las originales + aumentadas\n",
    "all_imgs_tensor = torch.cat([subset_tensor, aug_tensor], dim=0)   # [6600, 3, 32, 32]\n",
    "all_labels_tensor = torch.cat([subset_labels_tensor, aug_labels_tensor], dim=0)  # [6600]\n",
    "\n",
    "# Guardar en un archivo para no tener que descargar todo el dataset cifar10\n",
    "torch.save((all_imgs_tensor, all_labels_tensor), r\"C:\\Users\\denis\\Downloads\\cifar10_subset.pt\")\n",
    "print(\"Se guardaron correctamente las imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d076237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes: 6600\n",
      "Batch de imágenes: torch.Size([512, 3, 32, 32])\n",
      "Batch de etiquetas: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Cargar los tensores guardados en el archivo\n",
    "all_imgs_tensor, all_labels_tensor = torch.load(r\"C:\\Users\\denis\\Downloads\\cifar10_subset.pt\")\n",
    "print(\"Total imágenes:\", all_imgs_tensor.shape[0])\n",
    "\n",
    "# Crear el dataset\n",
    "dataset = TensorDataset(all_imgs_tensor, all_labels_tensor)\n",
    "\n",
    "# Train/Test Split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Random split para poder poner semilla\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Crear los dataloaders para hacerlos por batches\n",
    "train_loader = DataLoader(train_set, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=512, shuffle=False)\n",
    "\n",
    "# Verificar dimensiones y particiones\n",
    "imgs, labels = next(iter(train_loader))\n",
    "print(\"Batch de imágenes:\", imgs.shape)\n",
    "print(\"Batch de etiquetas:\", labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
