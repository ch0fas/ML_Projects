{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed15df2",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"https://samyzaf.com/ML/cifar10/cifar1.jpg\" width=\"380px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #bbc28d> **Trainning CNN'S - CIFAR Data Augmentation** </font>\n",
    "#### <font color= #2E9AFE> `Lab 2 - Machine Learning`</font>\n",
    "- <Strong> Sofía Maldonado, Diana Valdivia, Samantha Sánchez, Isabel Valladolid & Vivienne Toledo </Strong>\n",
    "- <Strong> Fecha </Strong>: 27/10/2025.\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Image retrieved from: https://samyzaf.com/ML/cifar10/cifar1.jpg</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592deb75",
   "metadata": {},
   "source": [
    "# <font color=#bbc28d>**Abstract**</font>\n",
    "This project focuses on building a **custom dataset** for an **image classification problem** using the **CIFAR-10** collection, which includes **10 distinct classes** of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15915405",
   "metadata": {},
   "source": [
    "# <font color=#bbc28d>**Configuration**</font>\n",
    "Basic configurations to make the process reproducible and also faster using CUDA if possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar la GPU o CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd1ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fijar un a semilla para reproducibilidad\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df52ec74",
   "metadata": {},
   "source": [
    "# <font color=#bbc28d>**Data Augmentation**</font>\n",
    "- **Selection:** 60 original images were chosen per class, ensuring a total of **600 base samples**.  \n",
    "- **Data Augmentation:** Each image was transformed using techniques such as  \n",
    "  - *Random horizontal flips*  \n",
    "  - *Rotations (±15°)*  \n",
    "  - *Color jittering* (brightness, contrast, saturation)  \n",
    "  - *Random resized cropping*  \n",
    "- **Result:** 10 augmented variants were generated for each image, producing **6,000 additional samples**, for a total of **6,600 images**.\n",
    "\n",
    "All images and labels were converted into **PyTorch tensors** and stored in a `.pt` file for reusability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f4699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardaron correctamente las imagenes\n"
     ]
    }
   ],
   "source": [
    "# Convertir a tensor las imágenes originales\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Data Augmentation: aplica variaciones aleatorias\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),        # voltea horizontalmente\n",
    "    transforms.RandomRotation(15),            # rota ±15 grados\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),    # cambia brillo, contraste y saturación\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # recorta aleatoriamente\n",
    "    transforms.ToTensor()\n",
    " ])\n",
    "\n",
    "# Descargar el dataset de Cifar-10\n",
    "base = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=to_tensor)\n",
    "\n",
    "# Seleccioanr del dataset original solo 60 imágenes por clase [Total=600]\n",
    "idxs = []\n",
    "for c in range(10):\n",
    "    count = 0\n",
    "    for i, (_, label) in enumerate(base):\n",
    "        if label == c:\n",
    "            idxs.append(i)\n",
    "            count += 1\n",
    "            if count == 60:\n",
    "                break\n",
    "\n",
    "subset_imgs = []\n",
    "subset_labels = []\n",
    "\n",
    "for i in idxs:\n",
    "    img, lbl = base[i]\n",
    "    subset_imgs.append(img)\n",
    "    subset_labels.append(lbl)\n",
    "\n",
    "# Con Data Augmentation generar 10 variantes por imagen [Total=600x10=6000]\n",
    "augmented_imgs = []\n",
    "augmented_labels = []\n",
    "\n",
    "for i, img in enumerate(subset_imgs):\n",
    "    lbl = subset_labels[i]\n",
    "    for j in range(10):\n",
    "        seed = SEED + i * 1000 + j\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        img_aug = augment(transforms.ToPILImage()(img))\n",
    "        augmented_imgs.append(img_aug)\n",
    "        augmented_labels.append(lbl)\n",
    "\n",
    "# convierte las listas de imágenes y etiquetas a tensores de PyTorch\n",
    "# Originales\n",
    "subset_tensor = torch.stack(subset_imgs)         # [600, 3, 32, 32]\n",
    "subset_labels_tensor = torch.tensor(subset_labels)  # [600]\n",
    "\n",
    "# Aumentadas\n",
    "aug_tensor = torch.stack(augmented_imgs)        # [6000, 3, 32, 32]\n",
    "aug_labels_tensor = torch.tensor(augmented_labels)  # [6000]\n",
    "\n",
    "# Juntar las originales + aumentadas\n",
    "all_imgs_tensor = torch.cat([subset_tensor, aug_tensor], dim=0)   # [6600, 3, 32, 32]\n",
    "all_labels_tensor = torch.cat([subset_labels_tensor, aug_labels_tensor], dim=0)  # [6600]\n",
    "\n",
    "# Guardar en un archivo para no tener que descargar todo el dataset cifar10\n",
    "torch.save((all_imgs_tensor, all_labels_tensor), r\"C:\\Users\\denis\\Downloads\\cifar10_subset.pt\")\n",
    "print(\"Se guardaron correctamente las imagenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f334b",
   "metadata": {},
   "source": [
    "This section loads the previously saved CIFAR-10 tensors and prepares them for model training. The dataset is created using `TensorDataset`, then divided into training (80%) and testing (20%) sets using a random split with a fixed seed to ensure reproducibility. Data loaders are built for both sets, allowing the data to be processed in batches of 512 images during training and evaluation. Finally, a sample batch is retrieved to confirm the dimensions of the images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d076237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes: 6600\n",
      "Batch de imágenes: torch.Size([512, 3, 32, 32])\n",
      "Batch de etiquetas: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Cargar los tensores guardados en el archivo\n",
    "all_imgs_tensor, all_labels_tensor = torch.load(r\"C:\\Users\\denis\\Downloads\\cifar10_subset.pt\")\n",
    "print(\"Total imágenes:\", all_imgs_tensor.shape[0])\n",
    "\n",
    "# Crear el dataset\n",
    "dataset = TensorDataset(all_imgs_tensor, all_labels_tensor)\n",
    "\n",
    "# Train/Test Split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Random split para poder poner semilla\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Crear los dataloaders para hacerlos por batches\n",
    "train_loader = DataLoader(train_set, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=512, shuffle=False)\n",
    "\n",
    "# Verificar dimensiones y particiones\n",
    "imgs, labels = next(iter(train_loader))\n",
    "print(\"Batch de imágenes:\", imgs.shape)\n",
    "print(\"Batch de etiquetas:\", labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
